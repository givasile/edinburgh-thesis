\subsection{Robust Optimistation Monte Carlo (ROMC) approach}
\label{sec:ROMC}

Apart from defining a tractable aproximation of the posterior, ROMC
provides a method for sampling from the posterior and computing an expectation.

\subsubsection*{Weighted Sampling}

Sampling could be performed in a straightforward fashion using
importance sampling; using the prior as the proposal distribution
$\thetab_i \sim p(\thetab)$ and computing the weight as
$w_i = \frac{L_{d,\epsilon}(\thetab_i)}{p(\thetab_i)}$. This approach
has the same drawbacks as ABC rejection sampling; when the prior is
wide or the dimensionality $D$ high, drawing a sample with non-zero
weight is rare, leading to either poor Effective Sample Size (ESS) or
huge execution time. The ROMC method proposes a better sampling
approach by constructing an appropriate proposal distribution $q_i$
per nuisance variable $\vb_i$\footnote{We describe the proposal area
  construction in the next chapter}. Therefore the weight is computed
as,

\begin{equation} \label{eq:sampling}
  w_{ij} = \frac{L_{d,\epsilon}(\thetab_{ij}) p(\thetab_{ij})}{q(\thetab_{ij})}, \thetab_{ij} \sim q_i(\thetab)
\end{equation}


\subsubsection*{Computing an expectation}

Having defined the procedure for obtaining weighted samples, any expectation $E_{p(\thetab|\data)}[h(\thetab)]$, can be approximated as,

\begin{equation} \label{eq:expectation}
  E_{p(\thetab|\data)}[h(\thetab)] \approx \frac{\sum_{ij} w_{ij} h(\thetab_{ij})}{\sum_{ij} w_{ij}}
\end{equation}

 
\subsubsection{Define and solve deterministic optimisation problems}

For each set of nuisance variables $\vb_i, i = \{1,2,...,n_1 \}$ a deterministic function is defined as $f_i(\thetab) = M_d(\thetab,\vb_i)$. For constructiong the proposal region, we search for a point $\thetab_* : d(f_i(\thetab_*), \data) < \epsilon$; this point can be obtained by solving the the following optimisation problem:

\begin{subequations}
\begin{alignat}{2}
&\!\min_{\thetab}        &\qquad& g_i(\thetab) = d(\data,  f_i(\thetab))\label{eq:optProb}\\
&\text{subject to} &      & g_i(\thetab) < \epsilon
\end{alignat}
\end{subequations}
%
We maintain a list of the solutions $\thetab_i^*$ of the optimisation problems. If for a specific set of nuisance variables $\vb_i$, there is no feasible solution we add nothing to the list. The optimisation problem~\ref{eq:optProb} can be treated as unconstrained, accepting the optimal point $\thetab_i^* = \text{argmin}_{\thetab}  g_i(\thetab)$ only if $g_i(\thetab_i^*) < \epsilon$.

\subsubsection{Gradient-Based Approach}
\label{subsubsec:GB_approach}

The nature of the generative model $M_r(\theta)$, specifies the properties of the objective function $g_i$. If $g_i$ is continuous with smooth gradients $\nabla_{\theta} g_i$ any gradient-based iterative algorithm can be used for solving~\ref{eq:optProb}. The gradients $\nabla_{\theta} g_i$ can be either provided in closed form or approximated by finite differences.

\subsubsection{Gaussian Process Approach}
\label{subsubsec:GP_approach}

In cases where the gradients are not available, the Bayesian Optimisation scheme provides an alternative choice. With this approach, apart from ontaining an optimal $\thetab_i^* $, a surrogate model $\hat{d}_i$ of the distance $g_i$ is fitted; this approximate model can be used in the following steps, instead of $g_i$, providing a noteworthy speed-up. Specifically, in the construction of the proposal region and in equations~\ref{eq:approx_posterior},~\ref{eq:sampling},~\ref{eq:expectation} it could replace $g_i$ in the evaluation of the indicator function~\ref{eq:indicator}, providing a major speed-up.

\subsubsection{Construction of the proposal area $q_i$}

Independently of the approach chosen above, the constraction of the proposal region follows a common method. The search directions $\mathbf{v}_d$ are computed as the eigenvectors of the curvature at $\theta_i^*$ and a line-search method is used to obtain the limit point where $g_i(\thetab_i^* + \kappa \vb_d) \geq \epsilon$. Algorithm~\ref{alg:region_construction} describes analytically the method.
