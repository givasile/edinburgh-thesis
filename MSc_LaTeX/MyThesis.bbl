% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.0 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{nty/global//global/global}
  \entry{Chen2019}{inproceedings}{}
    \name{author}{2}{}{%
      {{hash=CY}{%
         family={Chen},
         familyi={C\bibinitperiod},
         given={Yanzhi},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=GMU}{%
         family={Gutmann},
         familyi={G\bibinitperiod},
         given={Michael\bibnamedelima U},
         giveni={M\bibinitperiod\bibinitdelim U\bibinitperiod},
      }}%
    }
    \strng{namehash}{CYGMU1}
    \strng{fullhash}{CYGMU1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{C}
    \field{sortinithash}{C}
    \field{abstract}{%
    Approximate Bayesian computation (ABC) is a set of techniques for Bayesian
  inference when the likelihood is intractable but sampling from the model is
  possible. This work presents a simple yet effective ABC algorithm based on
  the combination of two classical ABC approaches â€” regression ABC and
  sequential ABC. The key idea is that rather than learning the posterior
  directly, we first target another auxiliary distribution that can be learned
  accurately by existing methods, through which we then subsequently learn the
  desired posterior with the help of a Gaussian copula. During this process,
  the complexity of the model changes adaptively according to the data at hand.
  Experiments on a synthetic dataset as well as three real-world inference
  tasks demonstrates that the proposed method is fast, accurate, and easy to
  use.%
    }
    \field{booktitle}{Proceedings of Machine Learning Research}
    \field{pages}{1584\bibrangedash 1592}
    \field{title}{{Adaptive Gaussian Copula ABC}}
    \verb{url}
    \verb http://proceedings.mlr.press/v89/chen19d.html
    \endverb
    \field{volume}{89}
    \verb{file}
    \verb :home/ntipakos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downl
    \verb oaded/Chen, Gutmann - 2019 - Adaptive Gaussian Copula ABC.pdf:pdf
    \endverb
    \field{year}{2019}
  \endentry

  \entry{Gutmann2016}{misc}{}
    \name{author}{2}{}{%
      {{hash=GMU}{%
         family={Gutmann},
         familyi={G\bibinitperiod},
         given={Michael\bibnamedelima U.},
         giveni={M\bibinitperiod\bibinitdelim U\bibinitperiod},
      }}%
      {{hash=CJ}{%
         family={Corander},
         familyi={C\bibinitperiod},
         given={Jukka},
         giveni={J\bibinitperiod},
      }}%
    }
    \keyw{Approximate Bayesian computation,Bayesian inference,Computational
  efficiency,Intractable likelihood,Latent variables}
    \strng{namehash}{GMUCJ1}
    \strng{fullhash}{GMUCJ1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{G}
    \field{sortinithash}{G}
    \field{abstract}{%
    Our paper deals with inferring simulator-based statistical models given
  some observed data. A simulator-based model is a parametrized mechanism which
  specifies how data are generated. It is thus also referred to as generative
  model. We assume that only a finite number of parameters are of interest and
  allow the generative process to be very general; it may be a noisy nonlinear
  dynamical system with an unrestricted number of hidden variables. This weak
  assumption is useful for devising realistic models but it renders statistical
  inference very difficult. The main challenge is the intractability of the
  likelihood function. Several likelihood-free inference methods have been
  proposed which share the basic idea of identifying the parameters by finding
  values for which the discrepancy between simulated and observed data is
  small. A major obstacle to using these methods is their computational cost.
  The cost is largely due to the need to repeatedly simulate data sets and the
  lack of knowledge about how the parameters affect the discrepancy. We propose
  a strategy which combines probabilistic modeling of the discrepancy with
  optimization to facilitate likelihood-free inference. The strategy is
  implemented using Bayesian optimization and is shown to accelerate the
  inference through a reduction in the number of required simulations by
  several orders of magnitude.%
    }
    \field{booktitle}{Journal of Machine Learning Research}
    \verb{eprint}
    \verb 1501.03291
    \endverb
    \field{issn}{15337928}
    \field{title}{{Bayesian optimization for likelihood-free inference of
  simulator-based statistical models}}
    \verb{file}
    \verb :home/ntipakos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downl
    \verb oaded/Gutmann, Corander - 2016 - Bayesian optimization for likelihood
    \verb -free inference of simulator-based statistical models.pdf:pdf
    \endverb
    \field{eprinttype}{arXiv}
    \field{year}{2016}
  \endentry

  \entry{Ikonomov2019}{article}{}
    \name{author}{2}{}{%
      {{hash=IB}{%
         family={Ikonomov},
         familyi={I\bibinitperiod},
         given={Borislav},
         giveni={B\bibinitperiod},
      }}%
      {{hash=GMU}{%
         family={Gutmann},
         familyi={G\bibinitperiod},
         given={Michael\bibnamedelima U.},
         giveni={M\bibinitperiod\bibinitdelim U\bibinitperiod},
      }}%
    }
    \strng{namehash}{IBGMU1}
    \strng{fullhash}{IBGMU1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{I}
    \field{sortinithash}{I}
    \field{abstract}{%
    This paper is on Bayesian inference for parametric statistical models that
  are implicitly defined by a stochastic simulator which specifies how data is
  generated. While exact sampling is possible, evaluating the likelihood
  function is typically prohibitively expensive. Approximate Bayesian
  Computation (ABC) is a framework to perform approximate inference in such
  situations. While basic ABC algorithms are widely applicable, they are
  notoriously slow and much research has focused on increasing their
  efficiency. Optimisation Monte Carlo (OMC) has recently been proposed as an
  efficient and embarrassingly parallel method that leverages optimisation to
  accelerate the inference. In this paper, we demonstrate a previously
  unrecognised important failure mode of OMC: It generates strongly
  overconfident approximations by collapsing regions of similar or
  near-constant posterior density into a single point. We propose an efficient,
  robust generalisation of OMC that corrects this. It makes fewer assumptions,
  retains the main benefits of OMC, and can be performed either as part of OMC
  or entirely as post-processing. We demonstrate the effectiveness of the
  proposed Robust OMC on toy examples and tasks in inverse-graphics where we
  perform Bayesian inference with a complex image renderer.%
    }
    \verb{eprint}
    \verb 1904.00670
    \endverb
    \field{title}{{Robust Optimisation Monte Carlo}}
    \verb{url}
    \verb http://arxiv.org/abs/1904.00670
    \endverb
    \verb{file}
    \verb :home/ntipakos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downl
    \verb oaded/Ikonomov, Gutmann - 2019 - Robust Optimisation Monte Carlo.pdf:
    \verb pdf
    \endverb
    \field{eprinttype}{arXiv}
    \field{year}{2019}
  \endentry

  \entry{Lintusaari2017}{article}{}
    \name{author}{5}{}{%
      {{hash=LJ}{%
         family={Lintusaari},
         familyi={L\bibinitperiod},
         given={Jarno},
         giveni={J\bibinitperiod},
      }}%
      {{hash=GMU}{%
         family={Gutmann},
         familyi={G\bibinitperiod},
         given={Michael\bibnamedelima U.},
         giveni={M\bibinitperiod\bibinitdelim U\bibinitperiod},
      }}%
      {{hash=DR}{%
         family={Dutta},
         familyi={D\bibinitperiod},
         given={Ritabrata},
         giveni={R\bibinitperiod},
      }}%
      {{hash=KS}{%
         family={Kaski},
         familyi={K\bibinitperiod},
         given={Samuel},
         giveni={S\bibinitperiod},
      }}%
      {{hash=CJ}{%
         family={Corander},
         familyi={C\bibinitperiod},
         given={Jukka},
         giveni={J\bibinitperiod},
      }}%
    }
    \keyw{ABC,Approximate Bayesian computation,Bayesian
  inference,Likelihood-free inference,Phylogenetics,Simulator-based
  models,Stochastic simulation models,Treebased models}
    \strng{namehash}{LJ+1}
    \strng{fullhash}{LJGMUDRKSCJ1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{L}
    \field{sortinithash}{L}
    \field{abstract}{%
    Bayesian inference plays an important role in phylogenetics, evolutionary
  biology, and in many other branches of science. It provides a principled
  framework for dealing with uncertainty and quantifying how it changes in the
  light of new evidence. For many complex models and inference problems,
  however, only approximate quantitative answers are obtainable. Approximate
  Bayesian computation (ABC) refers to a family of algorithms for approximate
  inference that makes a minimal set of assumptions by only requiring that
  sampling from a model is possible.We explain here the fundamentals of ABC,
  review the classical algorithms, and highlight recent developments.%
    }
    \verb{doi}
    \verb 10.1093/sysbio/syw077
    \endverb
    \field{issn}{1076836X}
    \field{number}{1}
    \field{pages}{e66\bibrangedash e82}
    \field{title}{{Fundamentals and recent developments in approximate Bayesian
  computation}}
    \field{volume}{66}
    \verb{file}
    \verb :home/ntipakos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downl
    \verb oaded/Lintusaari et al. - 2017 - Fundamentals and recent developments
    \verb  in approximate Bayesian computation.pdf:pdf
    \endverb
    \field{journaltitle}{Systematic Biology}
    \field{year}{2017}
  \endentry

  \entry{Meeds2015}{inproceedings}{}
    \name{author}{2}{}{%
      {{hash=ME}{%
         family={Meeds},
         familyi={M\bibinitperiod},
         given={Edward},
         giveni={E\bibinitperiod},
      }}%
      {{hash=WM}{%
         family={Welling},
         familyi={W\bibinitperiod},
         given={Max},
         giveni={M\bibinitperiod},
      }}%
    }
    \strng{namehash}{MEWM1}
    \strng{fullhash}{MEWM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{M}
    \field{sortinithash}{M}
    \field{abstract}{%
    We describe an embarrassingly parallel, anytime Monte Carlo method for
  likelihood-free models. The algorithm starts with the view that the
  stochasticity of the pseudo-samples generated by the simulator can be
  controlled externally by a vector of random numbers u, in such a way that the
  outcome, knowing u, is deterministic. For each instantiation of u we run an
  optimization procedure to minimize the distance between summary statistics of
  the simulator and the data. After reweighing these samples using the prior
  and the Jacobian (accounting for the change of volume in transforming from
  the space of summary statistics to the space of parameters) we show that this
  weighted ensemble represents a Monte Carlo estimate of the posterior
  distribution. The procedure can be run embarrassingly parallel (each node
  handling one sample) and anytime (by allocating resources to the worst
  performing sample). The procedure is validated on six experiments.%
    }
    \field{booktitle}{Advances in Neural Information Processing Systems}
    \verb{eprint}
    \verb 1506.03693
    \endverb
    \field{issn}{10495258}
    \field{title}{{Optimization Monte Carlo: Efficient and embarrassingly
  parallel likelihood-free inference}}
    \verb{file}
    \verb :home/ntipakos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downl
    \verb oaded/Meeds, Welling - 2015 - Optimization Monte Carlo Efficient and
    \verb embarrassingly parallel likelihood-free inference.pdf:pdf
    \endverb
    \field{eprinttype}{arXiv}
    \field{year}{2015}
  \endentry

  \entry{Tanaka2006}{article}{}
    \name{author}{4}{}{%
      {{hash=TMM}{%
         family={Tanaka},
         familyi={T\bibinitperiod},
         given={Mark\bibnamedelima M.},
         giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
      {{hash=FAR}{%
         family={Francis},
         familyi={F\bibinitperiod},
         given={Andrew\bibnamedelima R.},
         giveni={A\bibinitperiod\bibinitdelim R\bibinitperiod},
      }}%
      {{hash=LF}{%
         family={Luciani},
         familyi={L\bibinitperiod},
         given={Fabio},
         giveni={F\bibinitperiod},
      }}%
      {{hash=SSA}{%
         family={Sisson},
         familyi={S\bibinitperiod},
         given={S.\bibnamedelima A.},
         giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
      }}%
    }
    \strng{namehash}{TMM+1}
    \strng{fullhash}{TMMFARLFSSA1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{T}
    \field{sortinithash}{T}
    \field{abstract}{%
    Tuberculosis can be studied at the population level by genotyping strains
  of Mycobacterium tuberculosis isolated from patients. We use an approximate
  Bayesian computational method in combination with a stochastic model of
  tuberculosis transmission and mutation of a molecular marker to estimate the
  net transmission rate, the doubling time, and the reproductive value of the
  pathogen. This method is applied to a published data set from San Francisco
  of tuberculosis genotypes based on the marker IS6110. The mutation rate of
  this marker has previously been studied, and we use those estimates to form a
  prior distribution of mutation rates in the inference procedure. The
  posterior point estimates of the key parameters of interest for these data
  are as follows: net transmission rate, 0.69/year [95{\%} credibility interval
  (C.I.) 0.38, 1.08]; doubling time, 1.08 years (95{\%} C.I. 0.64, 1.82); and
  reproductive value 3.4 (95{\%} C.I. 1.4, 79.7). These figures suggest a
  rapidly spreading epidemic, consistent with observations of the resurgence of
  tuberculosis in the United States in the 1980s and 1990s. Copyright
  {\textcopyright} 2006 by the Genetics Society of America.%
    }
    \verb{doi}
    \verb 10.1534/genetics.106.055574
    \endverb
    \field{issn}{00166731}
    \field{title}{{Using approximate bayesian computation to estimate
  tuberculosis transmission parameters from genotype data}}
    \field{journaltitle}{Genetics}
    \field{year}{2006}
  \endentry
\enddatalist
\endinput
